{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMz0XmFFf/ftcQjRXBtet3L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElenaGomezB/AA_PRACTICA1_GRUPO_10/blob/main/Practica2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwFK2WEZgRje"
      },
      "source": [
        "#**PRÁCTICA 2 - REDES CONVOLUCIONALES**\n",
        "Grupo 10\n",
        "\n",
        "Elena Gómez \n",
        "\n",
        "Ana Muñoz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9JmR5mHgx7g"
      },
      "source": [
        "# **Objetivo**\n",
        "\n",
        "El  objetivo  de  esta  práctica  es  diseñar,  configurar  y  entrenar  un  modelo    Redes  de Neuronas Convolucionales. \n",
        "\n",
        "Crearemos un modelo  de Red  de  Neuronas  Convolucionales  que  sea  capaz  de  reconocer  y clasificar imágenes  de  ropa  en  sus  diferentes  tipologías.  Este  modelo  será  definido, \n",
        "configurado, entrenado, evaluado y mejorado para posteriormente usarlo para hacer predicciones.  \n",
        "\n",
        "Usaremos el conjunto de datos Fashion-MNIST, precargado en Keras.\n",
        "Fashion-MNIST  es  un  conjunto  de  datos  de  las  imágenes  de  los  artículos  de  Zalando. El conjunto de datos contiene 70K imágenes en escala de grises en 10 categorías.  Estas  imágenes  muestran  prendas  individuales  de  ropa  en  baja  resolución (28 x 28 píxeles)\n",
        "\n",
        "Se usan 60K imágenes para entrenar la red y 10K imágenes para evaluar la precisión con la que la red aprende a clasificar las imágenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0Gvr5NQhkV0"
      },
      "source": [
        "- Importamos **tensorflow** y comprobamos que la versión es 2.0.0 o superior "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h3urD15hq78"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nrh1HnEhuTv"
      },
      "source": [
        "- **Datos Fashion-MNIST**\n",
        "\n",
        "A continuación, cargamos las imágenes y creamos un vector de 10 elementos en el que a cada posición se le asigna el nombre de cada prenda. ('class_names')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRKzeG_Oh2G0",
        "outputId": "0884561f-1b9c-498e-9e73-81238ce20c3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Importamos las imágenes\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Creamos vector con las prendas\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FvI-2EGiI3D"
      },
      "source": [
        "- **Creamos redes convolucionales**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KXtB23zmEVb"
      },
      "source": [
        "**Caso 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBtzuGsiRU_",
        "outputId": "999d878e-1359-4c94-a1e4-94a8bdd03118",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(64, (7, 7), activation='relu', input_shape=(28, 28, 1)))\n",
        "model2.add(MaxPooling2D((2, 2)))\n",
        "model2.summary()\n",
        "#Explicacion summary:\n",
        "# [(7*7)+1]*64 = 3200 --> Obtenemos 64 matrices de 22*22\n",
        "#7*7 --> Tamaño de la ventana + 1--> umbral\n",
        "#Lo anterior * 64 filtros\n",
        "#En el maxpooling obtenemos 64 matriz de 11*11, no sale ningun parámetro ya que \n",
        "#no devuelve nada, simplemente aplica operaciones y reduce su tamaño"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 22, 22, 64)        3200      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 11, 11, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,200\n",
            "Trainable params: 3,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzYLdIEGi3Da",
        "outputId": "4feb9a4a-7af2-46e5-8369-40013bbe27fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model2.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D((2, 2)))\n",
        "model2.summary()\n",
        "#((3*3*64)+1)*128 --> matrices de 9*9\n",
        "#3*3(tamaño ventana)*64(filtros anteriores)+1(umbral)*128(filtros nuevos)\n",
        "#Con el Maxpooling obtenemos matrices de 4*4"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 22, 22, 64)        3200      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 11, 11, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 9, 9, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 77,056\n",
            "Trainable params: 77,056\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW5PWc2EkeP7",
        "outputId": "420bbf36-75b6-48cc-ea39-959c9da92742",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(65, activation='relu'))\n",
        "model2.add(Dense(10, activation='softmax'))\n",
        "model2.summary()\n",
        "#Flatten:\n",
        "#Antes tenemos que ajustar los tensores a la entrada de la capa\n",
        "#densa. Pasar de un tensor 3D a uno 1D (aplanar).\n",
        "#Nuestra salida (4,4,128) se debe pasar a un vector de \n",
        "#(4x4x128=2048) antes de aplicar softmax)\n",
        "#Primera capa densa:\n",
        "#(65*2048)+65\n",
        "#Segunda capa densa(softmax):\n",
        "#(10*65)+10"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 22, 22, 64)        3200      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 11, 11, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 9, 9, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 65)                133185    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                660       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 210,901\n",
            "Trainable params: 210,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBNlBRLGk2iQ",
        "outputId": "e805b9db-3574-4f86-c86d-8cf2013592bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "import tensorflow as tf\n",
        "\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "print (train_images.shape)\n",
        "print (train_labels.shape)\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "#train_labels = to_categorical(train_labels)\n",
        "#test_labels = to_categorical(test_labels)\n",
        "\n",
        "#etiquetas\n",
        "model2.add(layers.Flatten(input_shape=(28,28)))\n",
        "model3.add(layers.Flatten(input_shape=(28,28)))\n",
        "print (train_images.shape)\n",
        "print (train_labels.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(60000, 28, 28, 1)\n",
            "(60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhnBDxB2k-X1",
        "outputId": "6e7005cd-0537-4865-a66d-aeae9e538788",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model2.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.fit(train_images, train_labels,\n",
        "          batch_size=512,\n",
        "          epochs=5,\n",
        "          verbose=1)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "118/118 [==============================] - 82s 687ms/step - loss: 0.5189 - accuracy: 0.8111\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 82s 692ms/step - loss: 0.5119 - accuracy: 0.8151\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 82s 696ms/step - loss: 0.5073 - accuracy: 0.8163\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 83s 700ms/step - loss: 0.5002 - accuracy: 0.8194\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 83s 704ms/step - loss: 0.4957 - accuracy: 0.8222\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.5442 - accuracy: 0.7956\n",
            "Test accuracy: 0.7955999970436096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELH-qLY8mBXN"
      },
      "source": [
        "**Caso 3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh38lCKpmAtt"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Conv2D(64, (7, 7), activation='relu', input_shape=(28, 28, 1)))\n",
        "model3.add(MaxPooling2D((2, 2)))\n",
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqE71nAvmK_U"
      },
      "source": [
        "model3.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model3.add(MaxPooling2D((2, 2)))\n",
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh2QJumhmSfh"
      },
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(65, activation='relu'))\n",
        "model3.add(Dense(10, activation='softmax'))\n",
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAJR12OrmVaX"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "print (train_images.shape)\n",
        "print (train_labels.shape)\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "#train_labels = to_categorical(train_labels)\n",
        "#test_labels = to_categorical(test_labels)\n",
        "#etiquetas\n",
        "model2.add(layers.Flatten(input_shape=(28,28)))\n",
        "model3.add(layers.Flatten(input_shape=(28,28)))\n",
        "\n",
        "print (train_images.shape)\n",
        "print (train_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_HTXR5wmYVe"
      },
      "source": [
        "model3.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model3.fit(train_images, train_labels,\n",
        "          batch_size=512,\n",
        "          epochs=5,\n",
        "          verbose=1)\n",
        "\n",
        "test_loss, test_acc = model3.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eFvA2nxdVZf"
      },
      "source": [
        "#**PREDICCIONES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SDMixJUdpCN"
      },
      "source": [
        "# Veamos el elemento 6 de test y pintémoslo con matplotlib\n",
        "from keras.datasets import fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "digit = test_images[5]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()\n",
        "print (train_images.shape)\n",
        "print (train_labels.shape)\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "print (train_images.shape)\n",
        "print (train_labels.shape)\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "print(test_labels)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5Gi_G66fPBq"
      },
      "source": [
        "**modelo 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhvsXQUvdaI_"
      },
      "source": [
        "\n",
        "predictions = model2.predict(test_images)\n",
        "print(np.argmax(predictions[11]))\n",
        "print(predictions[11])\n",
        "np.sum(predictions[11])\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oglU-uafUVj"
      },
      "source": [
        "\n",
        "predictions = model3.predict(test_images)\n",
        "print(np.argmax(predictions[5]))\n",
        "print(predictions[5])\n",
        "np.sum(predictions[5])\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}