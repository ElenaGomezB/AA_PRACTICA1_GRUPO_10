{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMEryyDwHT1npncSvEtdmpk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElenaGomezB/AA_PRACTICA1_GRUPO_10/blob/main/Practica2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwFK2WEZgRje"
      },
      "source": [
        "#**PRÁCTICA 2 - REDES CONVOLUCIONALES**\n",
        "Grupo 10\n",
        "\n",
        "Elena Gómez \n",
        "\n",
        "Ana Muñoz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9JmR5mHgx7g"
      },
      "source": [
        "# **Objetivo**\n",
        "\n",
        "El  objetivo  de  esta  práctica  es  diseñar,  configurar  y  entrenar  un  modelo    Redes  de Neuronas Convolucionales. \n",
        "\n",
        "Crearemos un modelo  de Red  de  Neuronas  Convolucionales  que  sea  capaz  de  reconocer  y clasificar imágenes  de  ropa  en  sus  diferentes  tipologías.  Este  modelo  será  definido, \n",
        "configurado, entrenado, evaluado y mejorado para posteriormente usarlo para hacer predicciones.  \n",
        "\n",
        "Usaremos el conjunto de datos Fashion-MNIST, precargado en Keras.\n",
        "Fashion-MNIST  es  un  conjunto  de  datos  de  las  imágenes  de  los  artículos  de  Zalando. El conjunto de datos contiene 70K imágenes en escala de grises en 10 categorías.  Estas  imágenes  muestran  prendas  individuales  de  ropa  en  baja  resolución (28 x 28 píxeles)\n",
        "\n",
        "Se usan 60K imágenes para entrenar la red y 10K imágenes para evaluar la precisión con la que la red aprende a clasificar las imágenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0Gvr5NQhkV0"
      },
      "source": [
        "- Importamos **tensorflow** y comprobamos que la versión es 2.0.0 o superior "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h3urD15hq78",
        "outputId": "664a47ac-7b27-4a24-a22a-2b3e6ad0490a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)#"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nrh1HnEhuTv"
      },
      "source": [
        "- **Datos Fashion-MNIST**\n",
        "\n",
        "A continuación, cargamos las imágenes y creamos un vector de 10 elementos en el que a cada posición se le asigna el nombre de cada prenda. ('class_names')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRKzeG_Oh2G0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac0573be-724d-4567-b6d6-079c62988373"
      },
      "source": [
        "# Importamos las imágenes\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Creamos vector con las prendas\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FvI-2EGiI3D"
      },
      "source": [
        "- **Creamos redes convolucionales**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KXtB23zmEVb"
      },
      "source": [
        "**Caso 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBtzuGsiRU_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e9f6f8a-b4d1-43fa-bf00-db1ecf3a68ef"
      },
      "source": [
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(64, (7, 7), activation='relu', input_shape=(28, 28, 1)))\n",
        "model2.add(MaxPooling2D((2, 2)))\n",
        "model2.summary()\n",
        "#Explicacion summary:\n",
        "# [(7*7)+1]*64 = 3200 --> Obtenemos 64 matrices de 22*22\n",
        "#7*7 --> Tamaño de la ventana + 1--> umbral\n",
        "#Lo anterior * 64 filtros\n",
        "#En el maxpooling obtenemos 64 matriz de 11*11, no sale ningun parámetro ya que \n",
        "#no devuelve nada, simplemente aplica operaciones y reduce su tamaño"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 22, 22, 64)        3200      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 11, 11, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,200\n",
            "Trainable params: 3,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzYLdIEGi3Da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3845933c-19e1-4230-dc25-4194eb75f0ca"
      },
      "source": [
        "#añadimos una segunda capa convolucional\n",
        "model2.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D((2, 2)))\n",
        "model2.summary()\n",
        "#((3*3*64)+1)*128 --> matrices de 9*9\n",
        "#3*3(tamaño ventana)*64(filtros anteriores)+1(umbral)*128(filtros nuevos)\n",
        "#Con el Maxpooling obtenemos matrices de 4*4"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 22, 22, 64)        3200      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 11, 11, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 9, 9, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 77,056\n",
            "Trainable params: 77,056\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW5PWc2EkeP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "021ba3c7-875d-4bbc-e00b-d690aa6236dd"
      },
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(65, activation='relu'))\n",
        "model2.add(Dense(10, activation='softmax'))\n",
        "model2.summary()\n",
        "#Flatten:\n",
        "#Antes tenemos que ajustar los tensores a la entrada de la capa\n",
        "#densa. Pasar de un tensor 3D a uno 1D (aplanar).\n",
        "#Nuestra salida (4,4,128) se debe pasar a un vector de \n",
        "#(4x4x128=2048) antes de aplicar softmax)\n",
        "#Primera capa densa:\n",
        "#(65*2048)+65\n",
        "#Segunda capa densa(softmax):\n",
        "#(10*65)+10"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 22, 22, 64)        3200      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 11, 11, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 9, 9, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 65)                133185    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                660       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 210,901\n",
            "Trainable params: 210,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBNlBRLGk2iQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ae99f3-f2cd-4dec-80f9-a6b7cff5a7ac"
      },
      "source": [
        "#Antes de compilar y entrenar los modelos, preparamos los datos\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import tensorflow as tf\n",
        "\n",
        "#fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "#(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "print (train_images.shape)\n",
        "print (train_labels.shape)\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "#etiquetas\n",
        "model2.add(Flatten(input_shape=(28,28)))\n",
        "\n",
        "print (train_images.shape)\n",
        "print (train_labels.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(60000, 28, 28, 1)\n",
            "(60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhnBDxB2k-X1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b407a3b-bc2d-44b0-a943-9ea2a01e4888"
      },
      "source": [
        "model2.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.fit(train_images, train_labels,\n",
        "          batch_size=100,\n",
        "          epochs=5,\n",
        "          verbose=1)\n",
        "\n",
        "test_loss, test_acc = model2.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "600/600 [==============================] - 8s 12ms/step - loss: 0.7442 - accuracy: 0.7271\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.6397 - accuracy: 0.7634\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.5853 - accuracy: 0.7846\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.5452 - accuracy: 0.7994\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.5179 - accuracy: 0.8116\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.5271 - accuracy: 0.8075\n",
            "Test accuracy: 0.8075000047683716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELH-qLY8mBXN"
      },
      "source": [
        "**Caso 3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh38lCKpmAtt",
        "outputId": "5a843d54-e79a-4412-b9ed-cd3bb6fbb008",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Conv2D(64, (7, 7), activation='relu', input_shape=(28, 28, 1)))\n",
        "model3.add(MaxPooling2D((2, 2)))\n",
        "model3.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 22, 22, 64)        3200      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 11, 11, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,200\n",
            "Trainable params: 3,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqE71nAvmK_U",
        "outputId": "bff84be7-2965-4b7a-ad27-fa57aa820942",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model3.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model3.add(MaxPooling2D((2, 2)))\n",
        "model3.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 22, 22, 64)        3200      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 11, 11, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 9, 9, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 77,056\n",
            "Trainable params: 77,056\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh2QJumhmSfh",
        "outputId": "a5904780-623b-4604-9191-9dd20298b54e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(65, activation='relu'))\n",
        "model3.add(Dense(10, activation='softmax'))\n",
        "model3.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 22, 22, 64)        3200      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 11, 11, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 9, 9, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 65)                133185    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                660       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 210,901\n",
            "Trainable params: 210,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_HTXR5wmYVe",
        "outputId": "779cd529-a964-44a5-de54-cdf6fdc078ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model3.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model3.fit(train_images, train_labels,\n",
        "          batch_size=100,\n",
        "          epochs=5,\n",
        "          verbose=1)\n",
        "\n",
        "test_loss, test_acc = model3.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.5593 - accuracy: 0.7998\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 7s 11ms/step - loss: 0.3655 - accuracy: 0.8687\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 7s 11ms/step - loss: 0.3188 - accuracy: 0.8838\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 6s 11ms/step - loss: 0.2925 - accuracy: 0.8944\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 6s 11ms/step - loss: 0.2680 - accuracy: 0.9014\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.3370 - accuracy: 0.8775\n",
            "Test accuracy: 0.8774999976158142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eFvA2nxdVZf"
      },
      "source": [
        "#**PREDICCIONES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SDMixJUdpCN",
        "outputId": "360fbb9a-1bba-4310-ab24-80577384cd0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "# Veamos el elemento 6 de test y pintémoslo con matplotlib\n",
        "from keras.datasets import fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "digit = test_images[5]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()\n",
        "print (train_images.shape)\n",
        "print (train_labels.shape)\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "print (train_images.shape)\n",
        "print (train_labels.shape)\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "print(test_labels)\n",
        "print(test_labels[5])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(60000, 28, 28, 1)\n",
            "(60000,)\n",
            "[9 2 1 ... 8 1 5]\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5Gi_G66fPBq"
      },
      "source": [
        "**modelo 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhvsXQUvdaI_",
        "outputId": "5d7d60a1-ce30-4776-f15e-a4fb25a7f75b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "predictions = model2.predict(test_images)\n",
        "print(np.argmax(predictions[5]))\n",
        "print(predictions[5])\n",
        "np.sum(predictions[5])\n",
        "print(predictions)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "[1.5478255e-04 9.9956864e-01 1.3059085e-05 9.6005488e-06 2.4032200e-04\n",
            " 1.6051588e-07 1.3130769e-05 3.4395573e-09 3.4124395e-07 9.1050584e-10]\n",
            "[[3.4799112e-05 3.9662868e-06 3.3784727e-05 ... 1.5685707e-01\n",
            "  2.7815844e-03 8.0770284e-01]\n",
            " [2.4959801e-03 2.4472516e-07 9.6280843e-01 ... 7.8797907e-10\n",
            "  3.5059307e-05 2.3045159e-09]\n",
            " [9.1144839e-06 9.9997842e-01 1.8081579e-07 ... 4.4258952e-10\n",
            "  2.8970172e-08 1.6758032e-10]\n",
            " ...\n",
            " [1.6047664e-02 1.1431850e-05 5.2847579e-04 ... 3.8224931e-05\n",
            "  9.4688046e-01 5.8496689e-06]\n",
            " [6.2396587e-04 9.5913708e-01 8.9184839e-05 ... 7.1402019e-06\n",
            "  4.4058738e-06 9.0241847e-06]\n",
            " [8.3975756e-04 3.5990577e-04 1.1940280e-03 ... 1.3855678e-01\n",
            "  2.8170342e-02 1.3747235e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1eD8bqwmezD"
      },
      "source": [
        "**modelo 3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oglU-uafUVj",
        "outputId": "99c7d44e-bab8-485f-c826-e73f740d1b0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "predictions = model3.predict(test_images)\n",
        "print(np.argmax(predictions[5]))\n",
        "print(predictions[5])\n",
        "np.sum(predictions[5])\n",
        "print(predictions)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "[2.1008326e-04 9.9963236e-01 5.8357514e-06 6.9066377e-06 4.3666617e-07\n",
            " 1.2725671e-07 4.3625764e-06 3.2390951e-10 1.3976077e-04 8.1878220e-08]\n",
            "[[1.18991842e-07 2.35348523e-07 1.76190831e-08 ... 9.89672029e-04\n",
            "  1.00675325e-05 9.97823358e-01]\n",
            " [4.52959903e-05 5.65732634e-08 9.99866009e-01 ... 2.11651768e-12\n",
            "  2.06298273e-06 1.34019359e-07]\n",
            " [6.62091043e-06 9.99977112e-01 4.52423663e-08 ... 8.68429113e-12\n",
            "  5.42832822e-06 6.73954625e-09]\n",
            " ...\n",
            " [4.81485913e-05 6.67011335e-08 6.05566311e-05 ... 2.40420217e-09\n",
            "  9.99777496e-01 4.89368830e-08]\n",
            " [2.27513240e-07 9.99993563e-01 2.49958759e-07 ... 1.14513643e-08\n",
            "  1.19574068e-07 7.91923682e-08]\n",
            " [2.03829212e-03 2.36084132e-04 1.90885166e-05 ... 2.89689243e-01\n",
            "  5.15738726e-02 1.04203774e-02]]\n"
          ]
        }
      ]
    }
  ]
}