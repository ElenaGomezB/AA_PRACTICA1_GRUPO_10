{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNWJbUAUP09ODSYZn0U3Fk2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElenaGomezB/AA_PRACTICA1_GRUPO_10/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAnnkoDQ0o1N"
      },
      "source": [
        "#Grupo 10\n",
        "Elena Gomez \n",
        "\n",
        "Ana Muñoz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1ffu0Gu1qr0"
      },
      "source": [
        "##Objeto\n",
        "Crear un modelo de Red de Neuronas Artificiales que sea capaz de reconocer y clasificar imágenes de ropa en sus diferentes tipologías. Este modelo será definido, configurado, entrenado, evaluado y mejorado para posteriormente usarlo para hacer predicciones. \n",
        "\n",
        "El conjunto de datos viene dado en Fashion-MNIST, imágenes de los artículos de Zalando, tienda de moda online alemana especializada en ventas de ropa y zapatos. El conjunto de datos contiene 70K imágenes en escala de grises en 10 categorías. Estas imágenes muestran prendas individuales de ropa en baja resolución (28 x 28 píxeles)\n",
        "\n",
        "Usaremos 60K imágenes para entrenar la red y 10K imágenes para evaluar la precisión con la que la red aprende a clasificar las imágenes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmoxxGef222n"
      },
      "source": [
        "Importamos **tensorflow** y comprobamos que su versión es 2.0 superior"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CabHKxmkLANO",
        "outputId": "81f4f9a6-ff38-480b-81b6-7256ae91f695"
      },
      "source": [
        "# 1._ IMPORTAMOS KERAS\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(tf.keras.__version__)\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n",
            "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_bDPaU33Nmc"
      },
      "source": [
        "A continuación, cargamos las imágenes y creamos un vector del 0 al 9 en el que cada posición de asigna el nombre de cada prenda (class_names)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3AzS-hD_3q-",
        "outputId": "7a0e6a19-00df-4f1c-ad3c-31d8171a070c"
      },
      "source": [
        "# 2.- CARGAMOS EL CONJUNTO DE DATOS MINIST EN KERAS\n",
        "\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhEnDfCoChqn"
      },
      "source": [
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI2gP91VDmyG"
      },
      "source": [
        "Estudiamos y analizamos los datos de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62qhqxUaBIXC",
        "outputId": "c85e6dd3-91ef-4b27-cf67-f5ccef5f7bfa"
      },
      "source": [
        "print(train_images.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9MZl4k-DvjU",
        "outputId": "5d24c68e-b3ba-4185-a4f2-5872ed77d2da"
      },
      "source": [
        "# Vemos la matriz de la imagen número 5.000 (28x28)\n",
        "train_images[5000]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  44, 127,\n",
              "        182, 185, 161, 120,  55,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  42, 198, 251, 255,\n",
              "        251, 249, 247, 255, 252, 214, 100,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   2,   0,   0, 233, 252, 237, 239,\n",
              "        234, 237, 235, 237, 237, 254, 227,   0,   0,   0,   0,   1,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   2,   0,   0,  16, 210, 225, 215, 175,\n",
              "        217, 216, 193, 196, 226, 221, 209,  50,   0,   0,   2,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   2,   0,   0, 199, 229, 232, 230, 245, 204,\n",
              "        219, 253, 245, 207, 194, 223, 231, 236, 235,   0,   0,   3,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   1,   0, 137, 235, 204, 209, 201, 209, 234,\n",
              "        190, 234, 218, 215, 238, 239, 204, 189, 224, 154,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0, 194, 201, 200, 209, 202, 193, 205,\n",
              "        194, 183, 218, 231, 197, 172, 181, 193, 205, 199,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   3, 212, 203, 188, 189, 196, 198, 198,\n",
              "        201, 196, 217, 179, 167, 183, 217, 197, 202, 219,  30,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,  34, 225, 200, 194, 190, 188, 192, 196,\n",
              "        192, 170, 202, 190, 201, 195, 200, 201, 209, 227,  50,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,  68, 225, 210, 211, 198, 192, 196, 204,\n",
              "        196, 181, 212, 197, 195, 192, 206, 220, 210, 229,  93,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 111, 223, 227, 253, 209, 196, 204, 211,\n",
              "        206, 183, 216, 206, 210, 203, 215, 244, 224, 227, 150,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 139, 225, 224, 255, 202, 206, 212, 209,\n",
              "        211, 190, 213, 202, 207, 206, 222, 255, 230, 220, 190,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 180, 226, 224, 255, 199, 204, 207, 214,\n",
              "        214, 190, 216, 206, 203, 205, 219, 243, 224, 214, 234,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 225, 223, 228, 254, 209, 206, 208, 213,\n",
              "        210, 191, 215, 207, 204, 208, 211, 249, 226, 214, 255,  38,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 250, 232, 240, 239, 211, 203, 209, 205,\n",
              "        211, 197, 215, 208, 208, 214, 213, 239, 231, 219, 255,  81,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 248, 236, 247, 240, 203, 200, 208, 206,\n",
              "        214, 193, 213, 212, 208, 212, 211, 243, 242, 225, 254,  66,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 247, 230, 252, 226, 199, 211, 202, 211,\n",
              "        213, 182, 213, 212, 206, 202, 219, 207, 247, 222, 237, 104,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  10, 244, 219, 250, 205, 199, 209, 202, 209,\n",
              "        211, 189, 214, 206, 210, 200, 212, 154, 240, 208, 219, 140,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  21, 255, 222, 238, 184, 210, 192, 206, 209,\n",
              "        210, 189, 213, 211, 209, 192, 228, 155, 226, 238, 241, 166,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  37, 245, 226, 241, 150, 197, 189, 204, 209,\n",
              "        210, 183, 213, 213, 201, 184, 215, 146, 216, 236, 225, 154,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  58, 239, 227, 255, 158, 193, 195, 204, 209,\n",
              "        213, 180, 207, 217, 199, 194, 211, 158, 219, 236, 216, 151,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  68, 233, 226, 243, 139, 200, 193, 205, 210,\n",
              "        208, 180, 205, 212, 203, 196, 216, 157, 179, 255, 216, 155,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  81, 225, 224, 211, 138, 219, 185, 201, 213,\n",
              "        207, 197, 226, 212, 200, 190, 215, 183,  90, 255, 211, 147,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  91, 210, 230, 158, 114, 205, 187, 208, 209,\n",
              "        206, 193, 210, 211, 204, 195, 204, 181,  23, 255, 213, 158,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  87, 205, 232, 109, 164, 255, 214, 224, 222,\n",
              "        210, 197, 214, 225, 222, 211, 220, 217,   0, 234, 216, 169,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  92, 213, 232, 146,   5, 134, 151, 162, 170,\n",
              "        183, 182, 164, 166, 178, 162, 156,  98,   0, 240, 225, 210,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  43, 164, 206, 141,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0, 127, 125,  76,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtyF8clTEA3r",
        "outputId": "06d9f604-6098-41dc-f616-de81ac602ba8"
      },
      "source": [
        "# Sacamos la etiqueta de la imagen nº 5000\n",
        "train_labels[5000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYg8Oj-R4MLa"
      },
      "source": [
        "Pintamos la imagen 5000 usando matplotlib y vemos que su imagen corresponde con la etiqueta anterior, en este caso la etiqueta es 4 = Coat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "pEd7yIheBQM_",
        "outputId": "19cb6ae9-a797-4fda-9841-06b9d13161ba"
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "digit = train_images[5000]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASCElEQVR4nO3dX2yVdZoH8O/DP0EohdJSGoHtMIpgNAv1iGswE8U4UW9wbsxwQdgEp3OhyYzhQuNcjFfGbHZmMhebSTorDrOZdTIJYyTG7I5LJjGTEOIRWdtS1iIWKVbaQoGiyN9nL/piKvZ9nnre8573OM/3kzQ9PU/fnl8P/fK253l/v5+oKojo79+MogdARLXBsBMFwbATBcGwEwXBsBMFMauWD9bc3Kzt7e21fEiiUAYGBjA6OipT1TKFXUQeAfBrADMB/LuqvmR9fnt7O8rlcpaHJPqS1zYWmfJn/u9aqVRKrVX8a7yIzATwbwAeBXAHgC0ickelX4+I8pXlb/YNAI6o6lFVvQTgjwA2V2dYRFRtWcJ+C4Djkz4eTO77ChHpFJGyiJRHRkYyPBwRZZH7q/Gq2qWqJVUttbS05P1wRJQiS9hPAFgx6ePlyX1EVIeyhP0dALeJyHdEZA6AHwLYU51hEVG1Vdx6U9UrIvI0gP/GROttp6r2Vm1kNG09PT2ptd27d5vH7t+/36xfvXrVrC9btsysr127NrX24IMPmsfee++9Zj1iay2LTH12VX0TwJtVGgsR5YiXyxIFwbATBcGwEwXBsBMFwbATBcGwEwVR0/nsNLVDhw6Z9e3bt5t1a9rwlStXzGNnzbJ/BGbMsM8HXv2LL76o+NjVq1eb9R07dpj1J5980qxHwzM7URAMO1EQDDtREAw7URAMO1EQDDtREFLLjR1LpZJ+W1eXvXbtWmrNayF5Wltbzfro6KhZb2xsTK15/76zZ882617rbubMmWbdmyJrGRsbM+vLly8368ePHzfreSpq5dtSqYRyuTzlF+eZnSgIhp0oCIadKAiGnSgIhp0oCIadKAiGnSgITnFNWH10IFsv/cyZM2bd67PPnTvXrN98882ptTVr1pjHetNrvX6wN3arz/7xxx+bxy5atMisNzQ0mPUDBw6k1jo6OsxjPXn+vOSl/kZERLlg2ImCYNiJgmDYiYJg2ImCYNiJgmDYiYII02fPsy963333mfVjx46ZdW9sXq97ZGQktWb14Kfz2B9++KFZ93rlt99+e2qtvb3dPNabjz48PGzWH3744dSa9+9tPafTOd6bx++tA5CHTGEXkQEA4wCuAriiqqVqDIqIqq8aZ/YHVdVeSoWICse/2YmCyBp2BfAXEXlXRDqn+gQR6RSRsoiUvb+DiCg/WcN+v6p2AHgUwFMi8r0bP0FVu1S1pKqllpaWjA9HRJXKFHZVPZG8HwbwGoAN1RgUEVVfxWEXkfki0nD9NoDvA+ip1sCIqLqyvBrfCuC1pAc8C8B/qup/VWVUOci6Tvezzz6bWjty5Ih57MqVK826tza7N5/d2hbZ61XfeeedZv3s2bNm3Ztzbo1tYGDAPNazatUqs26tp3/06FHz2M7OKV+C+lJXV5dZL6KP7qk47Kp6FMA/VnEsRJQjtt6IgmDYiYJg2ImCYNiJgmDYiYIIM8U1a+tt3759qTWvBeQ9ttd687b/tdpfXgvIe+y7777brHtTYK1ltNeuXWse29bWZtYvXLhg1j/77LPUWlNTk3lsd3e3Wf824pmdKAiGnSgIhp0oCIadKAiGnSgIhp0oCIadKIgwfXaPt/Tv6dOnU2vz5s0zj124cKFZ95Z7vnTpUsX1m266yTz24sWLZj3rMtelUvqCwwsWLDCP9ba69qapLlmyJLU2a5b9oz86aq+h6i2h7U1rLgLP7ERBMOxEQTDsREEw7ERBMOxEQTDsREEw7ERBsM+e8LZVHh8fT615/eLLly+bda/n6/XKrWsEvPnq3tdeunSpWfeuAbDmlHtbLs+ZM8esL1682Kxbz4t3fYG1BDbg9+HZZyeiwjDsREEw7ERBMOxEQTDsREEw7ERBMOxEQbDPnvDmRls+//xzs271mgG/T+/1wq1eure2ujcX//z582bd+96tawi8Prq35r03tnPnzqXW5s+fbx7rrW/Q29tr1js6Osx6Edwzu4jsFJFhEemZdF+TiLwlIv3Je/vqBiIq3HR+jf8dgEduuO85AHtV9TYAe5OPiaiOuWFX1bcB3Lgm02YAu5LbuwA8XuVxEVGVVfoCXauqDiW3PwXQmvaJItIpImURKY+MjFT4cESUVeZX43Vi18HUnQdVtUtVS6paamlpyfpwRFShSsN+UkTaACB5b09fIqLCVRr2PQC2Jbe3AXi9OsMhory4fXYReRXAAwCaRWQQwM8BvATgTyKyHcAxAE/kOcha8PqmM2ak/784NjZmHnvixAmzftddd5l1r99s9dK9+ebeuvANDQ1m3Zsvb43N62V71xd4c85PnjyZWmtubjaP9Z7zffv2mfWtW7ea9SK4YVfVLSmlh6o8FiLKES+XJQqCYScKgmEnCoJhJwqCYScKglNcE4ODg2bdalF5bZqJiwzTeS0mb4qstVS1NzavdeYtuWy1JAFg9uzZZt3ijc1rvVnPm9dS9LbRPnz4sFmvRzyzEwXBsBMFwbATBcGwEwXBsBMFwbATBcGwEwXBPnuir6/PrFu9chHJ9NheL9ybCmr1sr1edFbeFFnrGgBvq2rv+/aOt5bo9q5t8Ja57unpMev1iGd2oiAYdqIgGHaiIBh2oiAYdqIgGHaiIBh2oiDYZ090d3ebdasXbvWSp8Pb9tibM57lGgCvV+3Nxc9yjYHXo/fqc+fONevWMtre1/Z4W5l98MEHZn316tWZHr8SPLMTBcGwEwXBsBMFwbATBcGwEwXBsBMFwbATBcE+e2JoaMisNzU1pda8OeOLFi0y617P15tbbfWTvV60d42At268x+rTe/PVvcf2evzW2u/e9+2tWe/xtgCvyz67iOwUkWER6Zl03wsickJEDiZvj+U7TCLKajq/xv8OwCNT3P8rVV2XvL1Z3WERUbW5YVfVtwGcrsFYiChHWV6ge1pE3k9+zV+c9kki0ikiZREpe9cTE1F+Kg37bwB8F8A6AEMAfpH2iarapaolVS21tLRU+HBElFVFYVfVk6p6VVWvAfgtgA3VHRYRVVtFYReRtkkf/gDAt29dXaJg3D67iLwK4AEAzSIyCODnAB4QkXUAFMAAgB/nOMaa8OaMW31Zrx/srVHu9cK9deWtfrM3H93rJ3v7q3u9buvre3Pps3zf3mN7e9571zZ4GhsbMx2fBzfsqrplirtfzmEsRJQjXi5LFATDThQEw04UBMNOFATDThQEp7gmvDaO1Yo5c+aMeax35aDXgjp//rxZnzdvXmrtwoUL5rHe9z1//nyznuUS6CxTVAFgbGzMrN96662ptcOHD5vHeq3YxYtTrxAH4C8lvWnTJrOeB57ZiYJg2ImCYNiJgmDYiYJg2ImCYNiJgmDYiYII02f3tkX2plMuWLAgtXbq1Cnz2ObmZrPu8Xq+eR0L+Mtke1NorSmy3lLS3tRgr37PPfek1j766CPzWG+KqndtRH9/v1kvAs/sREEw7ERBMOxEQTDsREEw7ERBMOxEQTDsREGE6bN7Swd7dWtZYm/O99KlS836J598Ytat7aIB4OzZs2bd4s0pz3q89bx51wB4S2wPDg6adesagIULF5rHHjt2zKx722x7W4AXgWd2oiAYdqIgGHaiIBh2oiAYdqIgGHaiIBh2oiDC9Nm9td2ttdcBe+6113NdtWqVWT937pxZ9/rRVt0bm8ebM+6xnjdvXXivz97Q0GDWrX9T77G96y68Pr21/kFR3DO7iKwQkb+KyCER6RWRnyT3N4nIWyLSn7y3V80nokJN59f4KwB2qOodAP4JwFMicgeA5wDsVdXbAOxNPiaiOuWGXVWHVPVAcnscQB+AWwBsBrAr+bRdAB7Pa5BElN03eoFORNoBrAewH0Crql6/APhTAK0px3SKSFlEyln2BSOibKYddhFZAGA3gJ+q6ldeUdKJGQdTzjpQ1S5VLalqydvgkIjyM62wi8hsTAT9D6r65+TukyLSltTbAAznM0Qiqga39SYTcxhfBtCnqr+cVNoDYBuAl5L3r+cywirx/oTwWkzWdEmvdeYtx2wttwwAly9fNutZWFNQAX+Jbe95s5bw9lqK3vLfWba69pax9nitWu95K8J0+uwbAWwF0C0iB5P7nsdEyP8kItsBHAPwRD5DJKJqcMOuqn8DkLZCwUPVHQ4R5YWXyxIFwbATBcGwEwXBsBMFwbATBRFmiqvXs50zZ45Zt5ZM9qYzLlmyxKwfOnTIrGe5BsDbUtn7vj3eUtLWNQRZe/xZrj9Ys2aNWX/jjTfMunc1qPe9FYFndqIgGHaiIBh2oiAYdqIgGHaiIBh2oiAYdqIgwvTZx8fHzbq3bLHVT25vb6/4WAA4deqUWfeWorbmy3tz6b0e/unTp8366OioWbeWXPb66FmufQDsbZO3bt1qHuv12b01CLyfpyLwzE4UBMNOFATDThQEw04UBMNOFATDThQEw04URJg+u7cFb2Njo1m31p3ftGmTeeyyZcvMurf1sLft8sWLF1NrXj/Y4x2/aNEis27Np/fmo3t1b9tlqw//0EPZFkb21p33ft6KwDM7URAMO1EQDDtREAw7URAMO1EQDDtREAw7URDT2Z99BYDfA2gFoAC6VPXXIvICgB8BuN6Afl5V38xroFl5/WJvr2+rX7x+/Xrz2P3795v19957z6x7a5xfuHAhtebN+fZ6/Fl74Vn2Z7906VLFXxuw92dvbW01j/XWhfeufajHPvt0Lqq5AmCHqh4QkQYA74rIW0ntV6r6r/kNj4iqZTr7sw8BGEpuj4tIH4Bb8h4YEVXXN/qbXUTaAawHcP330qdF5H0R2Skii1OO6RSRsoiUrUtOiShf0w67iCwAsBvAT1X1HIDfAPgugHWYOPP/YqrjVLVLVUuqWvL+DiKi/Ewr7CIyGxNB/4Oq/hkAVPWkql5V1WsAfgtgQ37DJKKs3LDLxMu5LwPoU9VfTrq/bdKn/QBAT/WHR0TVMp1X4zcC2AqgW0QOJvc9D2CLiKzDRDtuAMCPcxlhlXgtIm/JZUt/f79Zf+WVV8z6ypUrzfrY2JhZt9o83vflLbHtte68Za6tFpXVGgP86bNeO3Xjxo1m3eK1/ax2JwD09fVV/Nh5mc6r8X8DMNW/eN321Ino63gFHVEQDDtREAw7URAMO1EQDDtREAw7URBhlpJet26dWe/o6DDrvb29qTVveqzXD37xxRfNOtXeM888Y9a96bnetOci8MxOFATDThQEw04UBMNOFATDThQEw04UBMNOFIRYSyRX/cFERgAcm3RXM4DRmg3gm6nXsdXruACOrVLVHNs/qOqU67/VNOxfe3CRsqqWChuAoV7HVq/jAji2StVqbPw1nigIhp0oiKLD3lXw41vqdWz1Oi6AY6tUTcZW6N/sRFQ7RZ/ZiahGGHaiIAoJu4g8IiL/JyJHROS5IsaQRkQGRKRbRA6KSLngsewUkWER6Zl0X5OIvCUi/cn7KffYK2hsL4jIieS5OygijxU0thUi8lcROSQivSLyk+T+Qp87Y1w1ed5q/je7iMwE8AGAhwEMAngHwBZVPVTTgaQQkQEAJVUt/AIMEfkegPMAfq+qdyb3/QuA06r6UvIf5WJVfbZOxvYCgPNFb+Od7FbUNnmbcQCPA/hnFPjcGeN6AjV43oo4s28AcERVj6rqJQB/BLC5gHHUPVV9G8DpG+7eDGBXcnsXJn5Yai5lbHVBVYdU9UByexzA9W3GC33ujHHVRBFhvwXA8UkfD6K+9ntXAH8RkXdFpLPowUyhVVWHktufAmgtcjBTcLfxrqUbthmvm+euku3Ps+ILdF93v6p2AHgUwFPJr6t1SSf+Bqun3um0tvGulSm2Gf9Skc9dpdufZ1VE2E8AWDHp4+XJfXVBVU8k74cBvIb624r65PUddJP3wwWP50v1tI33VNuMow6euyK3Py8i7O8AuE1EviMicwD8EMCeAsbxNSIyP3nhBCIyH8D3UX9bUe8BsC25vQ3A6wWO5SvqZRvvtG3GUfBzV/j256pa8zcAj2HiFfkPAfysiDGkjGsVgP9N3nqLHhuAVzHxa91lTLy2sR3AEgB7AfQD+B8ATXU0tv8A0A3gfUwEq62gsd2PiV/R3wdwMHl7rOjnzhhXTZ43Xi5LFARfoCMKgmEnCoJhJwqCYScKgmEnCoJhJwqCYScK4v8BbvUvaRyWNaIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VK13H_muCVfB",
        "outputId": "34af592b-a025-472e-fdee-9413d5b6e1b8"
      },
      "source": [
        "#VSacamos las etiquetas de todas las imagenes de entrenamiento\n",
        "train_labels"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODXEGqJ2FQGj"
      },
      "source": [
        "Estudiamos ahora los datos de prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AGLoJY6FUro",
        "outputId": "fa691ac0-ce15-4b57-e1fb-5aeac13135a0"
      },
      "source": [
        "print(test_images.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hzpk9clJFhgN",
        "outputId": "dac2250f-a57a-416a-bca7-15976834c1d6"
      },
      "source": [
        "# Vemos la matriz de la imagen número 8.000 (28x28)\n",
        "test_images[8000]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
              "          0,   0,   0,  93, 153,   0,   0,   1,   0,   5,   7,   0,   1,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,   0,\n",
              "          0,   0, 148, 213, 229,  63,   0,   0,   0,   0,   0,   0,   0,\n",
              "         19,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,\n",
              "        165, 255, 225, 179, 196,  12,   0,   0,   0,   0, 172, 183, 100,\n",
              "        108,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  25, 108, 241,\n",
              "        222, 178, 178, 184, 192, 248,  57,   0,   0, 109, 228, 195, 174,\n",
              "          0,   0],\n",
              "       [  1,   0,   0,   0,   2,   3,   4,   0,   0,  97, 244, 215, 179,\n",
              "        152, 186, 207, 226, 217, 209, 255, 158,  96, 234, 201, 191, 191,\n",
              "         21,   0],\n",
              "       [  2,   3,   5,   0,   0,   0,   0,   9, 212, 219, 154, 123, 186,\n",
              "        203, 229, 241, 213, 211, 214, 211, 237, 250, 216, 191, 185, 208,\n",
              "         75,   0],\n",
              "       [  0,   0,   0,   0,   0,  14,  54, 133, 182, 143, 194, 217, 213,\n",
              "        211, 188, 171, 178, 218, 209, 212, 209, 196, 194, 185, 190, 189,\n",
              "         59,   0],\n",
              "       [  0,  28, 158, 198, 230, 210, 213, 200, 207, 218, 205, 197, 197,\n",
              "        205, 180, 214, 199, 208, 212, 214, 208, 194, 197, 202, 199, 182,\n",
              "         54,   0],\n",
              "       [ 66, 165, 169, 153, 168, 176, 173, 199, 203, 199, 196, 204, 213,\n",
              "        218, 218, 229, 226, 222, 222, 216, 202, 202, 199, 200, 194, 208,\n",
              "        156,   0],\n",
              "       [140, 187, 175, 176, 165, 166, 164, 158, 190, 215, 216, 211, 217,\n",
              "        210, 214, 207, 209, 208, 210, 200, 214, 205, 212, 210, 170, 170,\n",
              "        184,   0],\n",
              "       [ 38, 190, 177, 170, 187, 198, 196, 201, 196, 208, 198, 198, 191,\n",
              "        184, 188, 182, 187, 185, 174, 178, 170, 144, 137, 107, 131, 140,\n",
              "         50,   0],\n",
              "       [  0,  98, 183, 189, 178, 172, 164, 163, 164, 156, 115, 111, 104,\n",
              "        109, 132, 127,  96,  79, 112,  78,  96,  88,  90,  61, 102, 110,\n",
              "          0,  36],\n",
              "       [  0,   0,   1,  96, 154, 209, 218, 225, 211, 182, 187, 198, 174,\n",
              "        198, 214, 205, 194, 186, 234, 154, 163, 180, 163, 197, 179, 192,\n",
              "        180,  70],\n",
              "       [  0,   0,   0,   0,   0,   6,  36,  67,  73, 117,  98, 116, 124,\n",
              "        104,  57,  33,  34,  35,  39, 115, 130, 122, 121, 104,  90,  51,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVV_dvK8FoPG",
        "outputId": "ae7fa9f2-dd6e-4209-961a-f40392f9710c"
      },
      "source": [
        "# Vemos su etiqueta \n",
        "test_labels[8000]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "4UE6bd_TFu_1",
        "outputId": "8033bb9f-f990-4cb3-b112-da1df9e242e4"
      },
      "source": [
        "# Veamos el elemento 9000 y lo pintamos usando matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "digit = test_images[8000]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_LS4pHIF68J",
        "outputId": "d4c3c711-42ef-425d-d200-af7350948ac2"
      },
      "source": [
        "#Vemos las etiquetas de todas las imagenes segun esten ordenadas\n",
        "test_labels"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 1, ..., 8, 1, 5], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWJfN8bZGCPN"
      },
      "source": [
        "#CONSTRUIMOS NUESTRA RNA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1AM84Qs64A7"
      },
      "source": [
        "Vamos a crear 8 modelos diferentes, para todos la red sera secuencial (sin ciclos) y tendrá dos capas tipo Dense (densamente conectadas). Cambiaremos el optimizador, la función de activación y el número de neuronas de la primera capa.\n",
        "\n",
        "Cada una de las neuronas de la capa de entrada están conectadas con los 784 píxeles = 28*28. Dolo lo definimos para la primera capa; para la segunda capa y posteriores, Keras lo deduce.\n",
        "\n",
        "Para la segunda capa, la función de activación será siempre **softmax** ya que necesitamos la probabilidad de la clase a la que pertenece y 10 neuronas ya que tenemos 10 clases de prendas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyplA3cM7-G3"
      },
      "source": [
        "Los cuatro últimos modelos tendrán todos 512 neuronas en la primera capa\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oybrQEEm6aes"
      },
      "source": [
        "**Modelo 5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM75Szl7GHFV",
        "outputId": "41b2e3f3-e97b-435a-bb0a-5e96e455ef7f"
      },
      "source": [
        "#Funcion activacion: relu\n",
        "#Optimizador: sgd\n",
        "from keras import models\n",
        "from keras import layers\n",
        "network5 = models.Sequential()\n",
        "network5.add(layers.Dense(512, activation='relu', input_shape=(28*28,), name = 'capa1'))\n",
        "network5.add(layers.Dense(10, activation='softmax', name = 'capa2'))\n",
        "network5.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "capa1 (Dense)                (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "capa2 (Dense)                (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjdmPDoA-gxX"
      },
      "source": [
        "Como podemos ver, de la primera capa salen 401920 resultados; esto se debe a: (28* 28)*512+512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNKsLGdv-laI"
      },
      "source": [
        "**Modelo 6**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-vBv9_YP3BX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe3305f8-50c1-4203-8894-de9f92514821"
      },
      "source": [
        "#Funcion activacion: relu\n",
        "#Optimizador: rmsprop\n",
        "from keras import models\n",
        "from keras import layers\n",
        "network6 = models.Sequential()\n",
        "network6.add(layers.Dense(512, activation='relu', input_shape=(28*28,), name = 'capa1'))\n",
        "network6.add(layers.Dense(10, activation='softmax', name = 'capa2'))\n",
        "network6.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "capa1 (Dense)                (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "capa2 (Dense)                (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mqm3Og5w_CgS"
      },
      "source": [
        "**Modelo 7**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwNV4AraP-lS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5a14fb9-ad9a-4f1f-f3dc-16bc443aae79"
      },
      "source": [
        "#Funcion activacion: sigmoid\n",
        "#Optimizador: sgd\n",
        "from keras import models\n",
        "from keras import layers\n",
        "network7 = models.Sequential()\n",
        "network7.add(layers.Dense(512, activation='sigmoid', input_shape=(28*28,), name = 'capa1'))\n",
        "network7.add(layers.Dense(10, activation='softmax', name = 'capa2'))\n",
        "network7.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "capa1 (Dense)                (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "capa2 (Dense)                (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8g-bk6n_NgQ"
      },
      "source": [
        "**Modelo 8**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUPJtZ6eQGHH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a04fd395-10b1-4fb5-f986-e7ce984b0673"
      },
      "source": [
        "#Funcion activacion: sigmoid\n",
        "#Optimizador: rmsprop\n",
        "from keras import models\n",
        "from keras import layers\n",
        "network8 = models.Sequential()\n",
        "network8.add(layers.Dense(512, activation='sigmoid', input_shape=(28*28,), name = 'capa1'))\n",
        "network8.add(layers.Dense(10, activation='softmax', name = 'capa2'))\n",
        "network8.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "capa1 (Dense)                (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "capa2 (Dense)                (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrRJmz7_AFun"
      },
      "source": [
        "#**COMPILAMOS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_QD3ftLAzrz"
      },
      "source": [
        "Como algoritmo optimizador usamos tanto **rmsprop** (Root Mean Square Propagation) como **sgd** (Stocastic Gradient Descendent).\n",
        "\n",
        "Para la función de perdida elegimos **categorical_crossentropy** que se utiliza como señal de retroalimentación para aprender los tensores de peso y que la fase de entrenamiento intentará minimizar.\n",
        "\n",
        "Para la precisión utilizaremos **accuracy**: Solo tendremos en cuenta la fracción de imágenes que son correctamente clasificadas "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1m6fRte_53v"
      },
      "source": [
        "network5.compile(optimizer='sgd', \n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niUJ5Txb_5ur"
      },
      "source": [
        "network6.compile(optimizer='rmsprop', \n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcqqMkwi_5gx"
      },
      "source": [
        "network7.compile(optimizer='sgd', \n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKw6wsvmQkp9"
      },
      "source": [
        "network8.compile(optimizer='rmsprop', \n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZqgwKO2Bsfz"
      },
      "source": [
        "##PREPARAMOS LOS DATOS DE IMAGEN CON ALGUNA TRANSFORMACIÓN. NORMALIZACION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SVlAHsbB5p_"
      },
      "source": [
        "Antes del entrenamiento, preprocesaremos nuestros datos dándoles la forma que espera la red y escalando para que todos los valores estén en el intervalo [0, 1].Pasando de una matriz de forma (60000, 28, 28) con valores en el intervalo [0, 255] a una matriz de forma float32 con forma (60000, 28 * 28) con valores entre 0 y 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqTUWf0CZZm2",
        "outputId": "bff40e11-555a-48a2-85f5-fdf55f45349e"
      },
      "source": [
        "# Los tensores transformados tienen la misma cantidad de datos total que el \n",
        "# tensor inicial\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images, len(train_images), train_images.shape, train_images[3000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
              " 60000,\n",
              " (60000, 784),\n",
              " array([  0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   0,   0, 120,\n",
              "        131,  91, 147,  30,   0,   0,   1,   1,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,   0,   0,\n",
              "          0, 251, 199, 172, 195, 152,   0,   0,   0,   0,   3,   1,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         43, 124, 193, 166, 239, 255, 216, 172, 228, 126,  61,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         96, 167, 155, 159, 171, 178, 211, 215, 210, 196, 189, 158, 164,\n",
              "        159, 108,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  83, 157, 131, 117, 120, 148, 148, 145, 178, 159, 174, 160,\n",
              "        123, 132, 142, 172,  38,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0, 159, 128, 118, 120, 122, 112,  93, 124, 161, 109,\n",
              "        128, 128, 129, 146, 138, 167, 122,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0, 171, 135, 120, 114, 118, 119, 107, 125,\n",
              "        123, 117, 124, 124, 119, 145, 147, 166, 148,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   4, 171, 138, 126, 120, 117, 118,\n",
              "        102, 122, 145, 111, 120, 122, 120, 152, 154, 155, 170,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,  31, 170, 129, 138, 125,\n",
              "        113, 106, 103, 118, 137, 108, 135, 130, 158, 182, 138, 143, 186,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  58, 163, 114,\n",
              "        137, 143, 119, 103, 100, 109, 118, 109, 129, 134, 172, 181, 131,\n",
              "        136, 190,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  76,\n",
              "        160, 113, 141, 148, 128, 111, 101, 116, 137, 111, 131, 142, 167,\n",
              "        183, 136, 120, 186,  12,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 100, 148, 108, 147, 147, 134, 120, 105, 116, 131, 116, 136,\n",
              "        137, 165, 192, 137, 113, 187,  30,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0, 114, 143, 108, 158, 147, 130, 125, 106, 114, 122,\n",
              "        119, 129, 134, 160, 196, 136, 109, 182,  51,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0, 120, 140, 117, 151, 148, 131, 124, 109,\n",
              "        120, 143, 120, 130, 128, 159, 188, 111, 108, 178,  66,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0, 125, 129, 128, 112, 145, 140,\n",
              "        122, 113, 118, 134, 117, 132, 128, 166, 157,  91, 120, 170,  74,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0, 126, 123, 138,  74,\n",
              "        140, 143, 124, 111, 112, 126, 120, 130, 129, 175, 120,  88, 128,\n",
              "        164,  91,   0,   0,   0,   0,   0,   0,   0,   0,   0, 124, 123,\n",
              "        157,  45, 145, 143, 124, 113, 119, 148, 122, 131, 129, 183,  90,\n",
              "         73, 137, 155,  99,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        118, 122, 167,   0, 143, 149, 122, 112, 118, 137, 116, 132, 126,\n",
              "        183,  73,  50, 152, 147, 101,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0, 111, 128, 164,   0, 142, 151, 122, 111, 117, 132, 120,\n",
              "        136, 125, 182,  90,  18, 164, 145, 107,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 109, 132, 158,   0, 146, 148, 120, 108, 125,\n",
              "        157, 120, 136, 131, 176, 111,   0, 164, 143, 118,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0, 111, 141, 140,   0, 148, 149, 120,\n",
              "        114, 123, 137, 124, 137, 131, 171, 135,   0, 157, 147, 125,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0, 111, 154, 111,   0, 155,\n",
              "        148, 118, 116, 124, 143, 123, 131, 129, 167, 155,   0, 129, 157,\n",
              "        129,   0,   0,   0,   0,   0,   0,   0,   0,   0, 109, 155,  87,\n",
              "          0, 157, 145, 119, 117, 126, 154, 126, 130, 123, 161, 160,   0,\n",
              "         97, 163, 130,   0,   0,   0,   0,   0,   0,   0,   0,   0, 124,\n",
              "        142,  54,   0, 149, 141, 119, 119, 124, 136, 129, 126, 120, 153,\n",
              "        175,   0,  76, 145, 137,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 136, 151,  47,   0, 149, 137, 119, 118, 126, 143, 132, 130,\n",
              "        123, 153, 172,   0,  66, 148, 154,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0, 109, 174,  48,   0, 154, 138, 119, 117, 124, 138,\n",
              "        130, 129, 125, 159, 167,   0,  58, 174, 128,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,  85, 182, 147, 136,\n",
              "        143, 158, 146, 148, 153, 199,  70,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  26,\n",
              "         54,  72,  83,  96,  85,  80,  61,  14,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0], dtype=uint8))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Gv3HJbOZhxd",
        "outputId": "9c13a242-5eb9-4c3c-b3f8-7ad3ef7c33b2"
      },
      "source": [
        "train_images = train_images.astype('float32') / 255\n",
        "train_images, len(train_images), train_images.shape, train_images[3000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              " 60000,\n",
              " (60000, 784),\n",
              " array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.00392157, 0.00392157,\n",
              "        0.        , 0.        , 0.47058824, 0.5137255 , 0.35686275,\n",
              "        0.5764706 , 0.11764706, 0.        , 0.        , 0.00392157,\n",
              "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.01176471, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.9843137 , 0.78039217, 0.6745098 , 0.7647059 , 0.59607846,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
              "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.16862746, 0.4862745 , 0.75686276, 0.6509804 , 0.9372549 ,\n",
              "        1.        , 0.84705883, 0.6745098 , 0.89411765, 0.49411765,\n",
              "        0.23921569, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.3764706 , 0.654902  , 0.60784316, 0.62352943,\n",
              "        0.67058825, 0.69803923, 0.827451  , 0.84313726, 0.8235294 ,\n",
              "        0.76862746, 0.7411765 , 0.61960787, 0.6431373 , 0.62352943,\n",
              "        0.42352942, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.3254902 , 0.6156863 ,\n",
              "        0.5137255 , 0.45882353, 0.47058824, 0.5803922 , 0.5803922 ,\n",
              "        0.5686275 , 0.69803923, 0.62352943, 0.68235296, 0.627451  ,\n",
              "        0.48235294, 0.5176471 , 0.5568628 , 0.6745098 , 0.14901961,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.62352943, 0.5019608 , 0.4627451 , 0.47058824,\n",
              "        0.47843137, 0.4392157 , 0.3647059 , 0.4862745 , 0.6313726 ,\n",
              "        0.42745098, 0.5019608 , 0.5019608 , 0.5058824 , 0.57254905,\n",
              "        0.5411765 , 0.654902  , 0.47843137, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.67058825,\n",
              "        0.5294118 , 0.47058824, 0.44705883, 0.4627451 , 0.46666667,\n",
              "        0.41960785, 0.49019608, 0.48235294, 0.45882353, 0.4862745 ,\n",
              "        0.4862745 , 0.46666667, 0.5686275 , 0.5764706 , 0.6509804 ,\n",
              "        0.5803922 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.01568628, 0.67058825, 0.5411765 , 0.49411765,\n",
              "        0.47058824, 0.45882353, 0.4627451 , 0.4       , 0.47843137,\n",
              "        0.5686275 , 0.43529412, 0.47058824, 0.47843137, 0.47058824,\n",
              "        0.59607846, 0.6039216 , 0.60784316, 0.6666667 , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.12156863,\n",
              "        0.6666667 , 0.5058824 , 0.5411765 , 0.49019608, 0.44313726,\n",
              "        0.41568628, 0.40392157, 0.4627451 , 0.5372549 , 0.42352942,\n",
              "        0.5294118 , 0.50980395, 0.61960787, 0.7137255 , 0.5411765 ,\n",
              "        0.56078434, 0.7294118 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.22745098, 0.6392157 , 0.44705883,\n",
              "        0.5372549 , 0.56078434, 0.46666667, 0.40392157, 0.39215687,\n",
              "        0.42745098, 0.4627451 , 0.42745098, 0.5058824 , 0.5254902 ,\n",
              "        0.6745098 , 0.70980394, 0.5137255 , 0.53333336, 0.74509805,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.29803923, 0.627451  , 0.44313726, 0.5529412 , 0.5803922 ,\n",
              "        0.5019608 , 0.43529412, 0.39607844, 0.45490196, 0.5372549 ,\n",
              "        0.43529412, 0.5137255 , 0.5568628 , 0.654902  , 0.7176471 ,\n",
              "        0.53333336, 0.47058824, 0.7294118 , 0.04705882, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.39215687, 0.5803922 ,\n",
              "        0.42352942, 0.5764706 , 0.5764706 , 0.5254902 , 0.47058824,\n",
              "        0.4117647 , 0.45490196, 0.5137255 , 0.45490196, 0.53333336,\n",
              "        0.5372549 , 0.64705884, 0.7529412 , 0.5372549 , 0.44313726,\n",
              "        0.73333335, 0.11764706, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.44705883, 0.56078434, 0.42352942, 0.61960787,\n",
              "        0.5764706 , 0.50980395, 0.49019608, 0.41568628, 0.44705883,\n",
              "        0.47843137, 0.46666667, 0.5058824 , 0.5254902 , 0.627451  ,\n",
              "        0.76862746, 0.53333336, 0.42745098, 0.7137255 , 0.2       ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.47058824,\n",
              "        0.54901963, 0.45882353, 0.5921569 , 0.5803922 , 0.5137255 ,\n",
              "        0.4862745 , 0.42745098, 0.47058824, 0.56078434, 0.47058824,\n",
              "        0.50980395, 0.5019608 , 0.62352943, 0.7372549 , 0.43529412,\n",
              "        0.42352942, 0.69803923, 0.25882354, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.49019608, 0.5058824 , 0.5019608 ,\n",
              "        0.4392157 , 0.5686275 , 0.54901963, 0.47843137, 0.44313726,\n",
              "        0.4627451 , 0.5254902 , 0.45882353, 0.5176471 , 0.5019608 ,\n",
              "        0.6509804 , 0.6156863 , 0.35686275, 0.47058824, 0.6666667 ,\n",
              "        0.2901961 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.49411765, 0.48235294, 0.5411765 , 0.2901961 , 0.54901963,\n",
              "        0.56078434, 0.4862745 , 0.43529412, 0.4392157 , 0.49411765,\n",
              "        0.47058824, 0.50980395, 0.5058824 , 0.6862745 , 0.47058824,\n",
              "        0.34509805, 0.5019608 , 0.6431373 , 0.35686275, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.4862745 , 0.48235294,\n",
              "        0.6156863 , 0.1764706 , 0.5686275 , 0.56078434, 0.4862745 ,\n",
              "        0.44313726, 0.46666667, 0.5803922 , 0.47843137, 0.5137255 ,\n",
              "        0.5058824 , 0.7176471 , 0.3529412 , 0.28627452, 0.5372549 ,\n",
              "        0.60784316, 0.3882353 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.4627451 , 0.47843137, 0.654902  , 0.        ,\n",
              "        0.56078434, 0.58431375, 0.47843137, 0.4392157 , 0.4627451 ,\n",
              "        0.5372549 , 0.45490196, 0.5176471 , 0.49411765, 0.7176471 ,\n",
              "        0.28627452, 0.19607843, 0.59607846, 0.5764706 , 0.39607844,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.43529412,\n",
              "        0.5019608 , 0.6431373 , 0.        , 0.5568628 , 0.5921569 ,\n",
              "        0.47843137, 0.43529412, 0.45882353, 0.5176471 , 0.47058824,\n",
              "        0.53333336, 0.49019608, 0.7137255 , 0.3529412 , 0.07058824,\n",
              "        0.6431373 , 0.5686275 , 0.41960785, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.42745098, 0.5176471 , 0.61960787,\n",
              "        0.        , 0.57254905, 0.5803922 , 0.47058824, 0.42352942,\n",
              "        0.49019608, 0.6156863 , 0.47058824, 0.53333336, 0.5137255 ,\n",
              "        0.6901961 , 0.43529412, 0.        , 0.6431373 , 0.56078434,\n",
              "        0.4627451 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.43529412, 0.5529412 , 0.54901963, 0.        , 0.5803922 ,\n",
              "        0.58431375, 0.47058824, 0.44705883, 0.48235294, 0.5372549 ,\n",
              "        0.4862745 , 0.5372549 , 0.5137255 , 0.67058825, 0.5294118 ,\n",
              "        0.        , 0.6156863 , 0.5764706 , 0.49019608, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.43529412, 0.6039216 ,\n",
              "        0.43529412, 0.        , 0.60784316, 0.5803922 , 0.4627451 ,\n",
              "        0.45490196, 0.4862745 , 0.56078434, 0.48235294, 0.5137255 ,\n",
              "        0.5058824 , 0.654902  , 0.60784316, 0.        , 0.5058824 ,\n",
              "        0.6156863 , 0.5058824 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.42745098, 0.60784316, 0.34117648, 0.        ,\n",
              "        0.6156863 , 0.5686275 , 0.46666667, 0.45882353, 0.49411765,\n",
              "        0.6039216 , 0.49411765, 0.50980395, 0.48235294, 0.6313726 ,\n",
              "        0.627451  , 0.        , 0.38039216, 0.6392157 , 0.50980395,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.4862745 ,\n",
              "        0.5568628 , 0.21176471, 0.        , 0.58431375, 0.5529412 ,\n",
              "        0.46666667, 0.46666667, 0.4862745 , 0.53333336, 0.5058824 ,\n",
              "        0.49411765, 0.47058824, 0.6       , 0.6862745 , 0.        ,\n",
              "        0.29803923, 0.5686275 , 0.5372549 , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.53333336, 0.5921569 , 0.18431373,\n",
              "        0.        , 0.58431375, 0.5372549 , 0.46666667, 0.4627451 ,\n",
              "        0.49411765, 0.56078434, 0.5176471 , 0.50980395, 0.48235294,\n",
              "        0.6       , 0.6745098 , 0.        , 0.25882354, 0.5803922 ,\n",
              "        0.6039216 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.42745098, 0.68235296, 0.1882353 , 0.        , 0.6039216 ,\n",
              "        0.5411765 , 0.46666667, 0.45882353, 0.4862745 , 0.5411765 ,\n",
              "        0.50980395, 0.5058824 , 0.49019608, 0.62352943, 0.654902  ,\n",
              "        0.        , 0.22745098, 0.68235296, 0.5019608 , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.33333334, 0.7137255 , 0.5764706 ,\n",
              "        0.53333336, 0.56078434, 0.61960787, 0.57254905, 0.5803922 ,\n",
              "        0.6       , 0.78039217, 0.27450982, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.10196079, 0.21176471, 0.28235295, 0.3254902 ,\n",
              "        0.3764706 , 0.33333334, 0.3137255 , 0.23921569, 0.05490196,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        ], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke16AU59ZvNo"
      },
      "source": [
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSRvw7UXCpLv"
      },
      "source": [
        "##Preparación de etiquetas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxRe5M7ACswv"
      },
      "source": [
        "También tenemos que codificar categoricamente las etiquetas. Usaremos el **one-hot encoding**, que consiste en transformar las etiquetas en un vector de tantos ceros como el número de etiquetas distinta, y que contiene el valor de 1 en el índice que le corresponde al valor de la etiqueta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsj-uI7GZ8iA",
        "outputId": "bcd166b2-cf8e-44e0-bbc8-a7d6ca3add30"
      },
      "source": [
        "# from keras import utils\n",
        "# from keras.utils import to_categorical\n",
        "from keras.utils.np_utils import to_categorical\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "train_labels[5000] \n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hzZ9RxUDDwJ"
      },
      "source": [
        "Como hemos visto antes, la imagen 5000 corresponde con la etiqueta 4, y como podemos observar, el 1 aparece en la posición 4 del vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS-GMLs2aBQz",
        "outputId": "2f415e33-9cf1-494d-a424-c8fe8e653d52"
      },
      "source": [
        "#Caso 5\n",
        "network5.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.9968 - accuracy: 0.7040\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.7928\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.5785 - accuracy: 0.8123\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.5384 - accuracy: 0.8222\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.5123 - accuracy: 0.8299\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f391a2a9850>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNpPHtf4aQHf",
        "outputId": "33150b27-b3e2-4b27-f888-9ab3f0e5e8eb"
      },
      "source": [
        "network6.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5543 - accuracy: 0.8031\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3820 - accuracy: 0.8593\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3366 - accuracy: 0.8765\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.3112 - accuracy: 0.8858\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.2925 - accuracy: 0.8918\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3916bc8e90>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1ReFXMLaTpC",
        "outputId": "632507fc-dcd5-471b-a023-8e6754abf282"
      },
      "source": [
        "network7.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 4s 7ms/step - loss: 1.7023 - accuracy: 0.5807\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 1.1293 - accuracy: 0.7134\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 4s 7ms/step - loss: 0.9251 - accuracy: 0.7331\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.8229 - accuracy: 0.7454\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.7613 - accuracy: 0.7542\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f391a12ea10>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DL95dy3TaWgb",
        "outputId": "5115dc2d-b7de-4517-c3bc-c3c4c1ec7833"
      },
      "source": [
        "network8.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5915 - accuracy: 0.7901\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4271 - accuracy: 0.8449\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 0.3859 - accuracy: 0.8593\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3589 - accuracy: 0.8691\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.3389 - accuracy: 0.8759\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3916bb2b90>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR11VhpydMrE",
        "outputId": "4de26d2b-e683-4441-b7e6-2ec138baa086"
      },
      "source": [
        "test_loss, test_acc = network5.evaluate(test_images, test_labels)\n",
        "test_loss, test_acc = network6.evaluate(test_images, test_labels)\n",
        "test_loss, test_acc = network7.evaluate(test_images, test_labels)\n",
        "test_loss, test_acc = network8.evaluate(test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5264 - accuracy: 0.8218\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3675 - accuracy: 0.8694\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7511 - accuracy: 0.7526\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4055 - accuracy: 0.8538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcK6AcBAdef5",
        "outputId": "3b75646a-bb0b-4c0f-801c-2a8566727a23"
      },
      "source": [
        "print('test_acc:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc: 0.8537999987602234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "3sepKWtkdtxt",
        "outputId": "93956059-7a75-4775-f26b-08fb7bafdde5"
      },
      "source": [
        "#Predicciones\n",
        "# Veamos el elemento 5 de test y pintémoslo con matplotlib\n",
        "from keras.datasets import fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "import matplotlib.pyplot as plt\n",
        "digit = test_images[5]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25i_zkZwfFL0",
        "outputId": "ef077203-75e6-4dd6-e408-112ee65915e9"
      },
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "import numpy as np\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "\n",
        "print(test_labels)\n",
        "# train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "print(test_labels)\n",
        "\n",
        "predictions = network5.predict(test_images)\n",
        "print(np.argmax(predictions[5]))\n",
        "print(predictions[5])\n",
        "np.sum(predictions[5])\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[1. 0.]\n",
            "   [0. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[1. 0.]\n",
            "   [0. 1.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]]\n",
            "\n",
            "\n",
            " [[[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[1. 0.]\n",
            "   [0. 1.]]\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[1. 0.]\n",
            "   [0. 1.]]\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]]\n",
            "\n",
            "\n",
            " [[[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[1. 0.]\n",
            "   [0. 1.]]\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]]\n",
            "\n",
            "\n",
            " [[[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[0. 1.]\n",
            "   [1. 0.]]]]\n",
            "[[[[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  ...\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  [[[0. 1.]\n",
            "    [1. 0.]]\n",
            "\n",
            "   [[1. 0.]\n",
            "    [0. 1.]]]]\n",
            "\n",
            "\n",
            "\n",
            " [[[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  [[[0. 1.]\n",
            "    [1. 0.]]\n",
            "\n",
            "   [[1. 0.]\n",
            "    [0. 1.]]]\n",
            "\n",
            "\n",
            "  ...\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]]\n",
            "\n",
            "\n",
            "\n",
            " [[[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  [[[0. 1.]\n",
            "    [1. 0.]]\n",
            "\n",
            "   [[1. 0.]\n",
            "    [0. 1.]]]\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  ...\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]]\n",
            "\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            "\n",
            " [[[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  ...\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  [[[0. 1.]\n",
            "    [1. 0.]]\n",
            "\n",
            "   [[1. 0.]\n",
            "    [0. 1.]]]\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]]\n",
            "\n",
            "\n",
            "\n",
            " [[[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  [[[0. 1.]\n",
            "    [1. 0.]]\n",
            "\n",
            "   [[1. 0.]\n",
            "    [0. 1.]]]\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  ...\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]]\n",
            "\n",
            "\n",
            "\n",
            " [[[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  ...\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]\n",
            "\n",
            "\n",
            "  [[[1. 0.]\n",
            "    [0. 1.]]\n",
            "\n",
            "   [[0. 1.]\n",
            "    [1. 0.]]]]]\n",
            "5\n",
            "[0.10121062 0.08346012 0.08532996 0.09116425 0.06552476 0.22842282\n",
            " 0.10828454 0.0889231  0.08014075 0.06753907]\n",
            "[[0.10121062 0.08346012 0.08532996 ... 0.0889231  0.08014075 0.06753907]\n",
            " [0.10121062 0.08346012 0.08532996 ... 0.0889231  0.08014075 0.06753907]\n",
            " [0.10121062 0.08346012 0.08532996 ... 0.0889231  0.08014075 0.06753907]\n",
            " ...\n",
            " [0.10121062 0.08346012 0.08532996 ... 0.0889231  0.08014075 0.06753907]\n",
            " [0.10121062 0.08346012 0.08532996 ... 0.0889231  0.08014075 0.06753907]\n",
            " [0.10121062 0.08346012 0.08532996 ... 0.0889231  0.08014075 0.06753907]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "n7majqJih8Fd",
        "outputId": "acc90479-ae3a-4a2a-c9de-2f14b8cc9f12"
      },
      "source": [
        "#Esto es para el apartado 6\n",
        "i = 0\n",
        "plt.figure(figsize = (6,3))\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_image(i, predictions[i], test_labels, test_images)\n",
        "plt.subplot(1, 2, 2)\n",
        "plot_value_array(i, predictions[i], test_labels)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-0fa0e8e67443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplot_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplot_value_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plot_image' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}